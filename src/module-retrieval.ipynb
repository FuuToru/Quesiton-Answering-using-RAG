{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8930469,"sourceType":"datasetVersion","datasetId":5372293},{"sourceId":8930886,"sourceType":"datasetVersion","datasetId":5372584},{"sourceId":8931374,"sourceType":"datasetVersion","datasetId":5372913},{"sourceId":8944755,"sourceType":"datasetVersion","datasetId":5382474}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qq transformers[sentencepiece]==4.35.2 datasets==2.16.1 evaluate==0.4.1\n!sudo apt-get install -y libomp-dev\n!pip install -qq faiss-gpu\n!pip install -U langchain-community","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-13T11:59:06.806945Z","iopub.execute_input":"2024-07-13T11:59:06.807856Z","iopub.status.idle":"2024-07-13T12:00:14.665825Z","shell.execute_reply.started":"2024-07-13T11:59:06.807817Z","shell.execute_reply":"2024-07-13T12:00:14.664835Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngcsfs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\ns3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libomp-10-dev libomp5-10\nSuggested packages:\n  libomp-10-doc\nThe following NEW packages will be installed:\n  libomp-10-dev libomp-dev libomp5-10\n0 upgraded, 3 newly installed, 0 to remove and 75 not upgraded.\nNeed to get 351 kB of archives.\nAfter this operation, 2281 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libomp5-10 amd64 1:10.0.0-4ubuntu1 [300 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libomp-10-dev amd64 1:10.0.0-4ubuntu1 [47.7 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libomp-dev amd64 1:10.0-50~exp1 [2824 B]\nFetched 351 kB in 1s (666 kB/s)\nSelecting previously unselected package libomp5-10:amd64.\n(Reading database ... 113807 files and directories currently installed.)\nPreparing to unpack .../libomp5-10_1%3a10.0.0-4ubuntu1_amd64.deb ...\nUnpacking libomp5-10:amd64 (1:10.0.0-4ubuntu1) ...\nSelecting previously unselected package libomp-10-dev.\nPreparing to unpack .../libomp-10-dev_1%3a10.0.0-4ubuntu1_amd64.deb ...\nUnpacking libomp-10-dev (1:10.0.0-4ubuntu1) ...\nSelecting previously unselected package libomp-dev.\nPreparing to unpack .../libomp-dev_1%3a10.0-50~exp1_amd64.deb ...\nUnpacking libomp-dev (1:10.0-50~exp1) ...\nSetting up libomp5-10:amd64 (1:10.0.0-4ubuntu1) ...\nSetting up libomp-10-dev (1:10.0.0-4ubuntu1) ...\nSetting up libomp-dev (1:10.0-50~exp1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.14) ...\nCollecting langchain-community\n  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.6)\nCollecting langchain<0.3.0,>=0.2.7 (from langchain-community)\n  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\nCollecting langchain-core<0.3.0,>=0.2.12 (from langchain-community)\n  Downloading langchain_core-0.2.17-py3-none-any.whl.metadata (6.0 kB)\nCollecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n  Downloading langsmith-0.1.85-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.7->langchain-community)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.5.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.12->langchain-community)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.9.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.14.6)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nDownloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.2.7-py3-none-any.whl (983 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.17-py3-none-any.whl (366 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.1/366.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.85-py3-none-any.whl (127 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.7 langchain-community-0.2.7 langchain-core-0.2.17 langchain-text-splitters-0.2.2 langsmith-0.1.85 orjson-3.10.6 packaging-24.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom transformers import pipeline\nimport numpy as np\nimport collections\nimport torch\nimport faiss\nimport evaluate\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import AutoModelForQuestionAnswering\nfrom transformers import TrainingArguments, Trainer\nfrom tqdm.auto import tqdm\nfrom transformers import BertModel, BertTokenizer\nfrom datasets import Dataset, load_dataset\nimport torch\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:00:14.667734Z","iopub.execute_input":"2024-07-13T12:00:14.668019Z","iopub.status.idle":"2024-07-13T12:00:34.385012Z","shell.execute_reply.started":"2024-07-13T12:00:14.667994Z","shell.execute_reply":"2024-07-13T12:00:34.384025Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-13 12:00:21.694054: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-13 12:00:21.694188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-13 12:00:21.820850: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"file_path = \"../input/machine/machine_learning.pdf\"","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:00:34.386423Z","iopub.execute_input":"2024-07-13T12:00:34.387383Z","iopub.status.idle":"2024-07-13T12:00:34.392062Z","shell.execute_reply.started":"2024-07-13T12:00:34.387337Z","shell.execute_reply":"2024-07-13T12:00:34.391082Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"loader = PyPDFLoader(file_path = file_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:00:34.394561Z","iopub.execute_input":"2024-07-13T12:00:34.394944Z","iopub.status.idle":"2024-07-13T12:00:34.498556Z","shell.execute_reply.started":"2024-07-13T12:00:34.394908Z","shell.execute_reply":"2024-07-13T12:00:34.497799Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=500,\n    chunk_overlap=0,\n)\ndata = loader.load_and_split(text_splitter = text_splitter)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:39.733608Z","iopub.execute_input":"2024-07-13T12:02:39.734563Z","iopub.status.idle":"2024-07-13T12:02:39.799461Z","shell.execute_reply.started":"2024-07-13T12:02:39.734523Z","shell.execute_reply":"2024-07-13T12:02:39.798653Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:40.379716Z","iopub.execute_input":"2024-07-13T12:02:40.380671Z","iopub.status.idle":"2024-07-13T12:02:40.387129Z","shell.execute_reply.started":"2024-07-13T12:02:40.380638Z","shell.execute_reply":"2024-07-13T12:02:40.386029Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': '../input/machine/machine_learning.pdf', 'page': 0}, page_content='Machine learning is a subset of artiﬁcial intelligence (AI) focused on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions, relying instead on patterns and inference derived from data. The concept of machine learning was ﬁrst introduced in the mid-20th century by Arthur Samuel, who coined the term \"machine learning\" in 1959. Samuel deﬁned it as a \"ﬁeld of study that gives computers the ability to learn without being explicitly'),\n Document(metadata={'source': '../input/machine/machine_learning.pdf', 'page': 0}, page_content='programmed. \"  The ﬁeld of machine learning has seen signiﬁcant evolution since its inception. In the 1980s and 1990s, the development of deep learning and artiﬁcial neural networks marked a major advancement. A pivotal moment came in 1986 when GeoNrey Hinton and his colleagues introduced the backpropagation algorithm, which became a fundamental technique for training neural networks.  In recent years, machine learning has experienced tremendous growth due to advancements in computational power'),\n Document(metadata={'source': '../input/machine/machine_learning.pdf', 'page': 0}, page_content='and the explosion of data. Modern applications of machine learning are diverse, encompassing areas such as speech recognition, image recognition, natural language processing, recommendation systems, and industrial automation.  Prominent ﬁgures like GeoNrey Hinton, Yann LeCun, and Andrew Ng have made signiﬁcant contributions to the ﬁeld, pushing the'),\n Document(metadata={'source': '../input/machine/machine_learning.pdf', 'page': 1}, page_content='boundaries of what machine learning can achieve. Tools and libraries like TensorFlow, PyTorch, and scikit-learn have further democratized access to machine learning, making it easier for researchers and developers to create and deploy sophisticated models.')]"},"metadata":{}}]},{"cell_type":"code","source":"data[0].page_content","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:41.062592Z","iopub.execute_input":"2024-07-13T12:02:41.062967Z","iopub.status.idle":"2024-07-13T12:02:41.069493Z","shell.execute_reply.started":"2024-07-13T12:02:41.062938Z","shell.execute_reply":"2024-07-13T12:02:41.068467Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'Machine learning is a subset of artiﬁcial intelligence (AI) focused on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions, relying instead on patterns and inference derived from data. The concept of machine learning was ﬁrst introduced in the mid-20th century by Arthur Samuel, who coined the term \"machine learning\" in 1959. Samuel deﬁned it as a \"ﬁeld of study that gives computers the ability to learn without being explicitly'"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModel.from_pretrained('distilbert-base-uncased')\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:41.689816Z","iopub.execute_input":"2024-07-13T12:02:41.690513Z","iopub.status.idle":"2024-07-13T12:02:42.670397Z","shell.execute_reply.started":"2024-07-13T12:02:41.690481Z","shell.execute_reply":"2024-07-13T12:02:42.669598Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(document):\n    inputs = tokenizer(document, return_tensors='pt', truncation=True, padding=True, max_length=512)\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state.mean(dim=1)\n    return embeddings\n","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:42.672375Z","iopub.execute_input":"2024-07-13T12:02:42.673224Z","iopub.status.idle":"2024-07-13T12:02:42.678020Z","shell.execute_reply.started":"2024-07-13T12:02:42.673187Z","shell.execute_reply":"2024-07-13T12:02:42.677163Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"data[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:42.679551Z","iopub.execute_input":"2024-07-13T12:02:42.679963Z","iopub.status.idle":"2024-07-13T12:02:42.690954Z","shell.execute_reply.started":"2024-07-13T12:02:42.679931Z","shell.execute_reply":"2024-07-13T12:02:42.690048Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Document(metadata={'source': '../input/machine/machine_learning.pdf', 'page': 0}, page_content='Machine learning is a subset of artiﬁcial intelligence (AI) focused on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions, relying instead on patterns and inference derived from data. The concept of machine learning was ﬁrst introduced in the mid-20th century by Arthur Samuel, who coined the term \"machine learning\" in 1959. Samuel deﬁned it as a \"ﬁeld of study that gives computers the ability to learn without being explicitly')"},"metadata":{}}]},{"cell_type":"code","source":"#transform list to dict\ntexts = [doc.page_content for doc in data]\ndata_dict = {'context': texts}\nraw_datasets = Dataset.from_dict(data_dict)\n\nprint(raw_datasets)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:45.990991Z","iopub.execute_input":"2024-07-13T12:02:45.991937Z","iopub.status.idle":"2024-07-13T12:02:46.002277Z","shell.execute_reply.started":"2024-07-13T12:02:45.991902Z","shell.execute_reply":"2024-07-13T12:02:46.001360Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['context'],\n    num_rows: 4\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"EMBEDDING_COLUMN = 'page_content_embedding'\n\nembeddings_dataset = raw_datasets.map(\n    lambda x: {EMBEDDING_COLUMN: get_embeddings(x['context']).detach().cpu().numpy()[0]}\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:46.690669Z","iopub.execute_input":"2024-07-13T12:02:46.691363Z","iopub.status.idle":"2024-07-13T12:02:47.813628Z","shell.execute_reply.started":"2024-07-13T12:02:46.691330Z","shell.execute_reply":"2024-07-13T12:02:47.812203Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6233813ba5423cb078591925a7135e"}},"metadata":{}}]},{"cell_type":"code","source":"print(embeddings_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:47.815375Z","iopub.execute_input":"2024-07-13T12:02:47.815677Z","iopub.status.idle":"2024-07-13T12:02:47.820708Z","shell.execute_reply.started":"2024-07-13T12:02:47.815651Z","shell.execute_reply":"2024-07-13T12:02:47.819815Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['context', 'page_content_embedding'],\n    num_rows: 4\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings_dataset.add_faiss_index(column=EMBEDDING_COLUMN)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:02:47.822151Z","iopub.execute_input":"2024-07-13T12:02:47.822404Z","iopub.status.idle":"2024-07-13T12:02:47.846165Z","shell.execute_reply.started":"2024-07-13T12:02:47.822382Z","shell.execute_reply":"2024-07-13T12:02:47.845470Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"828a1dd8948547e1ad5ec8088f49921c"}},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['context', 'page_content_embedding'],\n    num_rows: 4\n})"},"metadata":{}}]},{"cell_type":"code","source":"input_question = 'When did backpropagation first appear?'\n\ninput_quest_embedding = get_embeddings([input_question]).cpu().detach().numpy()\n\nTOP_K = 5\nscores, samples = embeddings_dataset.get_nearest_examples(\n    EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n)\n\nfor idx, score in enumerate(scores):\n    print(f'Top {idx + 1}\\tScore: {score}')\n    print(f'Context: {samples[\"context\"][idx]}')\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:04:10.896273Z","iopub.execute_input":"2024-07-13T12:04:10.896904Z","iopub.status.idle":"2024-07-13T12:04:10.952937Z","shell.execute_reply.started":"2024-07-13T12:04:10.896873Z","shell.execute_reply":"2024-07-13T12:04:10.951943Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Top 1\tScore: 31.85853385925293\nContext: programmed. \"  The ﬁeld of machine learning has seen signiﬁcant evolution since its inception. In the 1980s and 1990s, the development of deep learning and artiﬁcial neural networks marked a major advancement. A pivotal moment came in 1986 when GeoNrey Hinton and his colleagues introduced the backpropagation algorithm, which became a fundamental technique for training neural networks.  In recent years, machine learning has experienced tremendous growth due to advancements in computational power\n\nTop 2\tScore: 33.920066833496094\nContext: and the explosion of data. Modern applications of machine learning are diverse, encompassing areas such as speech recognition, image recognition, natural language processing, recommendation systems, and industrial automation.  Prominent ﬁgures like GeoNrey Hinton, Yann LeCun, and Andrew Ng have made signiﬁcant contributions to the ﬁeld, pushing the\n\nTop 3\tScore: 34.91851806640625\nContext: Machine learning is a subset of artiﬁcial intelligence (AI) focused on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions, relying instead on patterns and inference derived from data. The concept of machine learning was ﬁrst introduced in the mid-20th century by Arthur Samuel, who coined the term \"machine learning\" in 1959. Samuel deﬁned it as a \"ﬁeld of study that gives computers the ability to learn without being explicitly\n\nTop 4\tScore: 44.32221603393555\nContext: boundaries of what machine learning can achieve. Tools and libraries like TensorFlow, PyTorch, and scikit-learn have further democratized access to machine learning, making it easier for researchers and developers to create and deploy sophisticated models.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"PIPELINE_NAME = 'question-answering'\nMODEL_NAME = 'FuuToru/distilbert-finetuned-squadv2'\npipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)\n\n# Use the results from the previous query (scores and samples)\nprint(f'Input question: {input_question}')\nfor idx, score in enumerate(scores):\n    question = input_question\n    context = samples[\"context\"][idx]\n    answer = pipe(\n        question=question,\n        context=context\n    )\n    print(f'Top {idx + 1}\\tScore: {score}')\n    print(f'Context: {context}')\n    print(f'Answer: {answer[\"answer\"]}')\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:04:16.686538Z","iopub.execute_input":"2024-07-13T12:04:16.686997Z","iopub.status.idle":"2024-07-13T12:04:17.767662Z","shell.execute_reply.started":"2024-07-13T12:04:16.686966Z","shell.execute_reply":"2024-07-13T12:04:17.766701Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Input question: When did backpropagation first appear?\nTop 1\tScore: 31.85853385925293\nContext: programmed. \"  The ﬁeld of machine learning has seen signiﬁcant evolution since its inception. In the 1980s and 1990s, the development of deep learning and artiﬁcial neural networks marked a major advancement. A pivotal moment came in 1986 when GeoNrey Hinton and his colleagues introduced the backpropagation algorithm, which became a fundamental technique for training neural networks.  In recent years, machine learning has experienced tremendous growth due to advancements in computational power\nAnswer: 1986\n\nTop 2\tScore: 33.920066833496094\nContext: and the explosion of data. Modern applications of machine learning are diverse, encompassing areas such as speech recognition, image recognition, natural language processing, recommendation systems, and industrial automation.  Prominent ﬁgures like GeoNrey Hinton, Yann LeCun, and Andrew Ng have made signiﬁcant contributions to the ﬁeld, pushing the\nAnswer: explosion of data\n\nTop 3\tScore: 34.91851806640625\nContext: Machine learning is a subset of artiﬁcial intelligence (AI) focused on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions, relying instead on patterns and inference derived from data. The concept of machine learning was ﬁrst introduced in the mid-20th century by Arthur Samuel, who coined the term \"machine learning\" in 1959. Samuel deﬁned it as a \"ﬁeld of study that gives computers the ability to learn without being explicitly\nAnswer: mid-20th century\n\nTop 4\tScore: 44.32221603393555\nContext: boundaries of what machine learning can achieve. Tools and libraries like TensorFlow, PyTorch, and scikit-learn have further democratized access to machine learning, making it easier for researchers and developers to create and deploy sophisticated models.\nAnswer: democratized access to machine learning\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class RAG:\n    def __init__(self, document):\n        self.document = document\n        self.model = AutoModel.from_pretrained('distilbert-base-uncased')\n        self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n    \n    def load_document(self):\n        loader = PyPDFLoader(file_path=self.document)\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n        data = loader.load_and_split(text_splitter=text_splitter)\n        texts = [doc.page_content for doc in data]\n        data_dict = {'context': texts}\n        raw_datasets = Dataset.from_dict(data_dict)\n        return raw_datasets\n    \n    def get_embeddings(self, document):\n        inputs = self.tokenizer(document, return_tensors='pt', truncation=True, padding=True, max_length=512)\n        with torch.no_grad():\n            outputs = self.model(**inputs)\n        embeddings = outputs.last_hidden_state.mean(dim=1)\n        return embeddings\n    \n    def compute_embeddings(self):\n        raw_datasets = self.load_document()\n        embeddings_dataset = raw_datasets.map(\n            lambda x: {'page_content_embedding': self.get_embeddings(x['context']).detach().cpu().numpy()[0]}\n        )\n        embeddings_dataset.add_faiss_index(column='page_content_embedding')\n        return embeddings_dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:05:16.065935Z","iopub.execute_input":"2024-07-13T12:05:16.066304Z","iopub.status.idle":"2024-07-13T12:05:16.076171Z","shell.execute_reply.started":"2024-07-13T12:05:16.066277Z","shell.execute_reply":"2024-07-13T12:05:16.075159Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"file_path = \"../input/machine/machine_learning.pdf\"","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:05:18.033649Z","iopub.execute_input":"2024-07-13T12:05:18.034023Z","iopub.status.idle":"2024-07-13T12:05:18.038388Z","shell.execute_reply.started":"2024-07-13T12:05:18.033992Z","shell.execute_reply":"2024-07-13T12:05:18.037521Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"rag_instance = RAG(document=file_path)\nembeddings_data = rag_instance.compute_embeddings()","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:05:18.667395Z","iopub.execute_input":"2024-07-13T12:05:18.667775Z","iopub.status.idle":"2024-07-13T12:05:20.741955Z","shell.execute_reply.started":"2024-07-13T12:05:18.667733Z","shell.execute_reply":"2024-07-13T12:05:20.740995Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8325866ed0c642989e0355b33fc7d435"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3847d31c16d42c3b0a74cac3b885d43"}},"metadata":{}}]},{"cell_type":"code","source":"question = \"In what year was the backpropagation algorithm developed?\"","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:07:42.049856Z","iopub.execute_input":"2024-07-13T12:07:42.050505Z","iopub.status.idle":"2024-07-13T12:07:42.054724Z","shell.execute_reply.started":"2024-07-13T12:07:42.050466Z","shell.execute_reply":"2024-07-13T12:07:42.053757Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"input_question = question\ninput_question_embedding = rag_instance.get_embeddings(input_question).cpu().detach().numpy()\n\nscores, samples = embeddings_data.get_nearest_examples(\n    \"page_content_embedding\", input_question_embedding, k=1\n)\n\nPIPELINE_NAME = 'question-answering'\nMODEL_NAME = 'FuuToru/distilbert-finetuned-squadv2'\npipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)\n\nprint(f'Input question: {input_question}\\n')\ncontext = samples[\"context\"][0]\nanswer = pipe(\n    question=input_question,\n    context=context\n)\nprint(f'Context: {context}\\n')\nprint(f'Answer: {answer[\"answer\"]}')","metadata":{"execution":{"iopub.status.busy":"2024-07-13T12:07:42.324396Z","iopub.execute_input":"2024-07-13T12:07:42.325054Z","iopub.status.idle":"2024-07-13T12:07:43.204454Z","shell.execute_reply.started":"2024-07-13T12:07:42.325022Z","shell.execute_reply":"2024-07-13T12:07:43.203153Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Input question: In what year was the backpropagation algorithm developed?\n\nContext: programmed. \"  The ﬁeld of machine learning has seen signiﬁcant evolution since its inception. In the 1980s and 1990s, the development of deep learning and artiﬁcial neural networks marked a major advancement. A pivotal moment came in 1986 when GeoNrey Hinton and his colleagues introduced the backpropagation algorithm, which became a fundamental technique for training neural networks.  In recent years, machine learning has experienced tremendous growth due to advancements in computational power\n\nAnswer: 1986\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}